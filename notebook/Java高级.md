[toc]

#1 JVM

## 内存结构

![内存模型](http://www.hollischuang.com/wp-content/uploads/2015/04/2354447461.jpg)

`堆(Heap)`和`非堆(Non-heap)`内存

堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给 自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法 的代码都在非堆内存中。

- 方法区：它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。默认最小值为16MB，最大值为64MB，可以通过`-XX:PermSize` 和 `-XX:MaxPermSize` 参数限制方法区的大小。常量池，用于存放编译器生成的各种符号引用。

  每一个Java类，在被JVM加载的时候，JVM会给这个类创建一个`instanceKlass`，保存在方法区；new创建一个对象的时候，JVM会创建一个`instanceOopDesc`对象

- 虚拟机栈：每个方法被执行的时候 都会创建一个“栈帧”用于存储**局部变量表**(包括参数)（存放了编译器可知的各种基本数据类型(`boolean`、`byte`、`char`、`short`、`int`、`float`、`long`、`double`)）、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。

- 本地方法栈：Native方法

- **堆**：各线程共用，存放了对象实例及数组(所有new的对象；其大小通过`-Xms`(最小值)和`-Xmx`(最大值)参数设置。**为了便于垃圾回收，Java堆空间分成三个区域，分别叫作New Generation, Old Generation或叫作Tenured Generation，还有Perm Space。**

  `堆内内存 = 新生代+老年代+持久代`

- 程序计数器：当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。

## 内存模型

![model](http://www.hollischuang.com/wp-content/uploads/2018/06/11.png)

**为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范**。JMM定义了一些语法集，这些语法集映射到Java语言中就是volatile`、`synchronized`、`final`、`concurren等关键字。

- 原子性：使用`synchronized`来保证方法和代码块内的操作是原子性的。
- 可见性：依赖主内存作为传递媒介，`volatile`关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。除了`volatile`，Java中的`synchronized`和`final`两个关键字也可以实现可见性。
- 有序性：`volatile`关键字会禁止指令重排。`synchronized`关键字保证同一时刻只允许一条线程操作。

[详见](https://github.com/hollischuang/toBeTopJavaer/blob/master/basics/jvm/java-memory-model.md)

## 对象模型

Java对象包含三部分：**对象头**、实例数据和对齐填充。

**对象头中包含锁状态标志、线程持有的锁等标志**

对象的实例（instantOopDesc)保存在堆上，对象的元数据（instantKlass）保存在方法区，对象的引用保存在栈上。

## 垃圾回收机制

1. 内存划分：新生代、旧生代、持久代；

- 新生代：大致分为Eden区和Survivor区，Survivor区又分为大小相同的两部分：FromSpace 和ToSpace。新建的对象都是用新生代分配内存，Eden空间不足的时候，会把存活的对象转移到Survivor中，新生代的大小可以由-Xmn来控制，也可以用-XX:SurvivorRatio来控制Eden和Survivor的比例.
- 旧生代：于存放新生代中经过多次垃圾回收仍然存活的对象，例如缓存对象。旧生代占用大小为-Xmx值减去-Xmn对应的值。
- 持久代：方法区；主要存放常量及类的一些信息默认最小值为16MB，最大值为64MB，可通过-XX:PermSize及-XX:MaxPermSize来设置最小值和最大值。

2. 算法：

- 复制算法（新生代）：一般Sun的JVM会将Eden区和Survivor区的比例调为8:1，保证有一块Survivor区是空闲的，这样，在垃圾回收的时候，将不需要进行回收的对象放在空闲的Survivor区，然后将Eden区和第一块Survivor区进行完全清理，这样有一个问题，就是如果第二块Survivor区的空间不够大怎么办？这个时候，就需要当Survivor区不够用的时候，暂时借持久代的内存用一下。
- 压缩算法（持久代）：将标记过的对象移动到一起，使得内存连续，这样，只要将标记边界以外的内存清理。

[JVM调优](http://ifeve.com/useful-jvm-flags/)

#2 Java高级概念

1. 包装类：

   Java提供了基本数据类型，这种数据的变量不需要使用new创建，他们不会在堆上创建，而是直接在栈内存中存储；但Java是一种面向对象语言，很多地方都需要使用对象而不是基本数据类型。比如，在集合类中，我们是无法将int 、double等类型放进去的。因为集合的容器要求元素是Object类型。

   装箱：基本数据类型转换成包装类的过程；反之为拆包；

   ```
   Integer i =10;  //自动装箱
   int b= i;     //自动拆箱
   ```

   自动装箱都是通过包装类的`valueOf()`方法来实现的.自动拆箱都是通过包装类对象的`xxxValue()`来实现的。

```java
Integer integer=Integer.valueOf(1); 
int i=integer.intValue(); 
```

2. 反射：

   - 动态加载：所谓静态加载就是在编译时刻必须加载的所有可能使用到的类，但有时只需要在运行时刻时加载，即动态加载类，可通过类类型创建

     ```Class c = Class.forName(args[0])```

     ```实例化：xxx ins=（xxx）c.newInstance()```

     args[0]表示需要使用到的类名称；

     xxx表示某个接口；

   - 基本类型皆存在类类型：比如int.class 

     对象的类类型：obj.getClass()

     普通类的类类型：Class.forName(...)

     **要获取类信息，首先获取类类型**；

   - 相关方法：

     - 获取类名称：c.getName()
     - 获取类方法(父类方法及自雷所有public方法）：c.getMethods()
     - 获取该类自己声明的所有方法（无视访问权限）:c.getDeclaredMethods()
     - 获取返回值类型的类类型：Class type=c.getReturnType()
     - 获取参数类型的类类型：Class [] paratype=c.getParameterType()

   - Field:

     - 获取成员变量:```Field [] fs = c.getFields();c.getDeclaredFields()```
     - 获取成员变量的类类型：c.getType()
     - 获取成员变量的名字：c.getName()

   - 获取构造函数：（构造函数也是对象）

     - Constructor [] cs = c.getDeclaredConstructor();
     - c.getName()
     - Class[] para=c.getParameterTypes()

   - 方法的反射： 

     - 获取某个方法：

       ```java
       A a = new A()
       Class c = a.getClass();
       //c.getMethod("MethodName",para[])
       //c.getMethod("print",new Class[]{int.class,int.class})
       Method m = c.getMethod("print",int.class,int.class);
        //a.print(10,20)
       //Object o = m.invoke(a,new Object[]{10,20});
       Object o = m.invoke(a,10,20);
       ```

3. 序列化：将对象的状态信息转换为可以存储或传输的形式的过程，一般转化为字节或是XML等格式，反之，其过程为反序列化；对象序列化可实现对象持久化；对象的序列化与反序列化被广泛应用到RMI(远程方法调用)及网络传输中。

4. JMS(Java Message Service)：提供标准的产生、发送、接收消息的接口简化企业应用的开发；
   - P2P 模型规定了一个消息只能有一个接收者;消息生产者产生一个消息后，把这个消息发送到一个Queue（队列）中，然后消息接收者再从这个Queue中读取；
   - Pub/Sub 模型允许一个消息可以有多个接收者。消息生产者产生一个消息后，把这个消息发送到一个Topic中，这个Topic可以同时有多个接收者在监听，当一个消息到达这个Topic之后，所有消息接收者都会收到这个消息；

5. 泛型：

   - 常见标识符：E：element（集合），T：Type（java类）；K –Key（键）V – Value（值）N – Number（数值类型）？ – 表示不确定的java类型（无限制通配符类型）；

   - 写法：class Hello<T>{...}；T的具体类型由实例化决定

     ​	

# 3 [设计模式](http://www.hollischuang.com/archives/3709)

- 创建型模式：下述三者逐步抽象化

  - 简单工厂模式：根据外界给定的信息，决定究竟应该创建哪个具体类的对象；

  - 工厂方法模式：

    ```IFactory factory = new AddFactory();```

    ```Operation operationAdd =  factory.CreateOption();```

    IFactory工厂接口，AddFactory具体方法的工厂方法类（implement上述接口）；

    Operation操作类，实例化具体操作

    核心的工厂类不再负责所有产品的创建，而是将具体创建工作交给子类去做。这个核心类仅仅负责给出具体工厂必须实现的接口，而不负责产品类被实例化这种细节，这使得工厂方法模式可以允许系统在不修改工厂角色的情况下引进新产品。

  - 抽象工厂模式

类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离；外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节，使整个系统的设计更加符合单一职责原则；**之所以名字中包含工厂模式四个字，是因为对象的实例化过程是通过工厂实现的，是用工厂代替new操作的。**

简单工厂 ： 用来生产同一等级结构中的任意产品。（对于增加新的产品，主要是新增产品，就要修改工厂类。符合单一职责原则。不符合开放-封闭原则）

工厂方法 ：用来生产同一等级结构中的固定产品。（支持增加任意产品，新增产品时不需要更改已有的工厂，需要增加该产品对应的工厂。符合单一职责原则、符合开放-封闭原则。但是引入了复杂性）

抽象工厂 ：用来生产不同产品族的全部产品。（增加新产品时，需要修改工厂，增加产品族时，需要增加工厂。符合单一职责原则，部分符合开放-封闭原则，降低了复杂性）

#4 锁

当并发事务同时访问一个资源时，有可能导致数据不一致，因此需要一种机制来将数据访问顺序化，以保证数据库数据的一致性。

**分类**：

一、按操作划分，可分为`DML锁`、`DDL锁`

二、按锁的粒度划分，可分为[`表级锁`](https://47.99.194.156/archives/914)、[`行级锁`](https://47.99.194.156/archives/914)、[`页级锁`](https://47.99.194.156/archives/914)（mysql）

三、按锁级别划分，可分为[`共享锁`](https://47.99.194.156/archives/923)、[`排他锁`](https://47.99.194.156/archives/923)

四、按加锁方式划分，可分为`自动锁`、`显示锁`

五、按使用方式划分，可分为[`乐观锁`](https://47.99.194.156/archives/934)、[`悲观锁`](https://47.99.194.156/archives/934)

## 数据库的锁机制

- 行级锁(INNODB引擎)：只针对当前操作的行进行加锁，其加锁粒度最小，但加锁的开销也最大，行级锁分为**[`共享锁`](https://47.99.194.156/archives/923)** 和 **[`排他锁`](https://47.99.194.156/archives/923)**。

  **开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。**

- 表级锁(MYISAM引擎)：对当前操作的整张表加锁；表级锁定分为**`表共享读锁`（[共享锁](https://47.99.194.156/archives/923)）**与**`表独占写锁`（[排他锁](https://47.99.194.156/archives/923)）**。

  **开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。**

- 页级锁(BDB引擎 )：页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。

  **开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般**

- 共享锁：共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改；

  - SELECT ... LOCK IN SHARE MODE;
  - Mysql会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。

- 排他锁：写锁，事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。

  - SELECT ... FOR UPDATE;
  - Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。

- 意向锁：表级锁，其设计目的主要是为了在一个事务中揭示下一行将要被请求锁的类型。**意向锁是InnoDB自动加的，不需要用户干预。**

## 乐观锁及悲观锁

- 悲观锁：借助数据库锁机制在修改数据之前先锁定，再修改的方式被称之为悲观并发控制；所谓悲观是指：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改；适用于**多写场景**；

  > 在对任意记录进行修改前，先尝试为该记录加上[排他锁](https://47.99.194.156/archives/923)（exclusive locking）。
  >
  > 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。
  >
  > 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。
  >
  > 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

- 乐观锁：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用**版本号机制和CAS算法**实现。适用于**多读场景**；

## 分布式锁

- 基于数据库实现分布式锁（复杂性低）
-  基于缓存（redis，memcached，tair）实现分布式锁 （性能高）
- 基于Zookeeper实现分布式锁（可靠性高）

## synchronized锁

### JVM同步机制

堆，上面存放着所有对象；方法区，上面存放着静态变量。为了协调多个线程之间的共享数据访问，虚拟机给每个对象和类都分配了一个锁。这个锁就像一个特权，在同一时刻，只有一个线程可以“拥有”这个类或者对象。

每个**监视器**都与一个对象相关联。当线程执行到监视器监视下的代码块中的第一条指令时，线程必须获取对被引用对象的锁定。在线程获取锁之前，他是无法执行这段代码的，一旦获得锁，线程便可以进入“被保护”的代码开始执行。当线程离开代码块的时候，无论如何离开，都会释放所关联对象的锁。

### synchronized

解决并发编程的原子性（同一时间只能被一个线程访问），可见性（一个线程修改了这个变量的值，其他线程能够立即看得到修改的值），有序性问题（as-if-serial语义：在Java中，不管怎么排序，都不能影响单线程程序的执行结果，所有硬件优化的前提都是必须遵守as-if-serial语义；synchronized通过排他锁的方式就保证了同一时间内，被synchronized修饰的代码是单线程执行的，单线程的有序性就天然存在）。

`synchronized`有两种使用形式，同步方法和同步代码块；被`synchronized`修饰的代码块及方法，在同一时间，只能被单个线程访问。

无论是`ACC_SYNCHRONIZED`还是`monitorenter`、`monitorexit`都是基于Monitor实现的，在Java虚拟机(HotSpot)中，Monitor是基于C++实现的，由ObjectMonitor实现。

- 同步方法：同步方法的常量池中会有一个`ACC_SYNCHRONIZED`标志（标记同步）。当某个线程要访问某个方法的时候，会检查是否有`ACC_SYNCHRONIZED`，如果有设置，则需要先获得监视器锁，然后开始执行方法，方法执行之后再释放监视器锁。这时如果其他线程来请求执行方法，会因为无法获得监视器锁而被阻断住。

- 同步代码块：使用`monitorenter`和`monitorexit`两个指令实现。可以把执行`monitorenter`指令理解为加锁，执行`monitorexit`理解为释放锁。 每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0，当一个线程获得锁（执行`monitorenter`）后，该计数器自增变为 1 ，当同一个线程再次获得该对象的锁的时候，计数器再次自增。当同一个线程释放锁（执行`monitorexit`指令）的时候，计数器再自减。当计数器为0的时候。锁将被释放，其他线程便可以获得锁。

### 锁优化

对于线程来说，一共有五种状态，分别为：初始状态(New) 、就绪状态(Runnable) 、运行状态(Running) 、阻塞状态(Blocked) 和死亡状态(Dead) 

`synchronized`的实现方式中使用`Monitor`进行加锁，这是一种互斥锁，为了表示他对性能的影响我们称之为**重量级锁**。这种互斥锁在互斥同步上对性能的影响很大，Java的线程是映射到操作系统原生线程之上的，如果要阻塞或唤醒一个线程就需要操作系统的帮忙，这就要从用户态转换到内核态，因此状态转换需要花费很多的处理器时间。

其实，**共享数据的锁定状态一般只会持续很短的一段时间**。在JIT编译过程中，虚拟机会根据情况使用下述三种技术对锁进行优化，目的是减少锁的竞争，提升性能。

- 自旋（JDK1.6默认开启）：如果物理机上有多个处理器，可以让多个线程同时执行的话。我们就可以让后面来的线程“稍微等一下”，但是并不放弃处理器的执行时间，看看持有锁的线程会不会很快释放锁。**自旋锁和阻塞锁最大的区别就是，到底要不要放弃处理器的执行时间。对于阻塞锁和自旋锁来说，都是要等待获得共享资源。但是阻塞锁是放弃了CPU时间，进入了等待区，等待被唤醒。而自旋锁是一直“自旋”在那里，时刻的检查共享资源是否可以被访问。**
  - 如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。
- 锁消除：JIT编译器对内部锁的具体实现所做的一种优化。如果JIT经过逃逸分析之后发现并无线程安全问题的话，就会做锁消除。
- 锁粗化：大部分情况下，减小锁的粒度是很正确的做法，只有一种特殊的情况下，会发生一种叫做锁粗化的优化。如果在一段代码中连续的对同一个对象反复加锁解锁，其实是相对耗费资源的，这种情况可以适当放宽加锁的范围，减少性能消耗。

## volatile锁

“轻量级的`synchronized`”，`volatile`是一个**变量修饰符**，只能用来修饰变量。无法修饰方法及代码块等；

对于`volatile`变量，当对`volatile`变量进行写操作的时候，JVM会向处理器发送一条lock前缀的指令，将这个缓存中的变量回写到系统主存中。

但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现`缓存一致性协议`；

**缓存一致性协议**：每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。

如果一个变量被`volatile`所修饰的话，在每次数据变化之后，其值都会被强制刷入主存。而其他处理器的缓存由于遵守了缓存一致性协议，也会把这个变量的值从主存加载到自己的缓存中。这就保证了一个`volatile`在并发编程中，其值在多个缓存中是可见的。

- 原子性：**线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。当一个线程获得时间片之后开始执行，在时间片耗尽之后，就会失去CPU使用权。所以在多线程场景下，由于时间片在线程间轮换，就会发生原子性问题**。因其与字节码指令`monitorenter`和`monitorexit`无关，所以**不能保证原子性的**。

- 可见性：被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。
- 有序性：通过**内存屏障**来来禁止指令重排的，保证了代码的程序会严格按照代码的先后顺序执行。**内存屏障（Memory Barrier）**是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。

# 5 扩展

## Zookeeper

分布式服务协调组件。将那些复杂的、容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并提供一系列简单易用的接口给用户使用。

在整个集群刚刚启动的时候，会进行Leader选举，当Leader确定之后，其他机器自动成为Follower，并和Leader建立长连接，用于数据同步和请求转发等。当有客户端机器的写请求落到follower机器上的时候，follower机器会把请求转发给Leader，由Leader处理该请求，比如数据的写操作，在请求处理完之后再把数据同步给所有的follower。

分布式领域，有一个著名的理论——[CAP理论](https://47.99.194.156/archives/666)：任何软件系统都无法同时满足一致性、可用性以及分区容错性。

ZooKeeper是个CP（**一致性+分区容错性**）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性;但是它不能保证每次服务请求的可用性。

## 消息队列

1. 异步：常见的B/S架构下，客户端向服务器发送请求，但是服务器处理这个消息需要花费的时间很长的时间，如果客户端一直等待服务器处理完消息，会造成客户端的系统资源浪费；而使用消息队列后，服务器直接将消息推送到消息队列中，由专门的处理消息程序处理消息，这样客户端就不必花费大量时间等待服务器的响应了；
2. 解耦：传统的软件开发模式，模块之间的调用是直接调用，这样的系统很不利于系统的扩展，同时，模块之间的相互调用，数据之间的共享问题也很大，每个模块都要时时刻刻考虑其他模块会不会挂了；使用消息队列以后，模块之间不直接调用，而是通过数据，且当某个模块挂了以后，数据仍旧会保存在消息队列中。最典型的就是**生产者-消费者**模式，本案例使用的就是该模式；
3. 削峰填谷：某一时刻，系统的并发请求暴增，远远超过了系统的最大处理能力后，如果不做任何处理，系统会崩溃；使用消息队列以后，服务器把请求推送到消息队列中，由专门的处理消息程序以合理的速度消费消息，降低服务器的压力。

# Hash

在Java中，保存数据有两种比较简单的数据结构：数组和链表。**数组的特点是：寻址容易，插入和删除困难；而链表的特点是：寻址困难，插入和删除容易。**常用的哈希函数的冲突解决办法中有一种方法叫做链地址法，其实就是将数组和链表组合在一起，发挥了两者的优势，我们可以将其理解为链表的数组。

![](https://47.99.194.156/wp-content/uploads/2018/03/640.png)

我们根据元素的自身特征把元素分配到不同的链表中去，反过来我们也正是通过这些特征找到正确的链表，再从链表中找出正确的元素。其中，根据元素特征计算元素数组下标的方法就是哈希算法.

## HashMap

hash方法的功能是根据Key来定位这个K-V在链表数组中的位置：Object Key--> int(数组下标)；

扩容：HashMap就像一个“桶”，那么capacity就是这个桶“当前”最多可以装多少元素，而size表示这个桶已经装了多少元素。当HashMap中的元素个数（size）超过临界值（threshold）时就会自动扩容：threshold = loadFactor * capacity。loadFactor是装载因子，表示HashMap满的程度，默认值为0.75f；

具体来讲：一般调用Object对象的hashCode()方法，该方法会返回一个整数，然后用这个数对HashMap或者HashTable的容量进行取模；实际上，由两个方法`int hash(Object k)`（该方法主要是将Object转换成一个整型）和`int indexFor(int h, int length)`（该方法主要是将hash生成的整型转换成链表数组中的下标）来实现；

```java
final int hash(Object k) {
    int h = hashSeed;
    if (0 != h && k instanceof String) {
        return sun.misc.Hashing.stringHash32((String) k);
    }

    h ^= k.hashCode();
    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}

static int indexFor(int h, int length) {
    return h & (length-1);//取模 h%length 
  //提升性能
}
```

## HashTable

线程安全；

- HashMap默认的初始化大小为16，之后每次扩充为原来的2倍。
- HashTable默认的初始大小为11，之后每次扩充为原来的2n+1。
- 当哈希表的大小为素数时，简单的取模哈希的结果会更加均匀，所以单从这一点上看，HashTable的哈希表大小选择，似乎更高明些。因为hash结果越分散效果越好。
- 在取模计算时，如果模数是2的幂，那么我们可以直接使用位运算来得到结果，效率要大大高于做除法。所以从hash计算的效率上，又是HashMap更胜一筹。
- 但是，HashMap为了提高效率使用位运算代替哈希，这又引入了哈希分布不均匀的问题，所以HashMap为解决这问题，又对hash算法做了一些改进，进行了扰动计算（ConcurrentHashMap）。

[参考](https://www.hollischuang.com/archives/2091)

